# -*- coding: utf-8 -*-
"""Dataset_creation_AST_tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18RWG4JV1KaaY046XMLuegGysIvAo053-
"""

#!git clone https://github.com/AliOsm/AI-SOCO.git

#pip install libclang

import sys
import clang.cindex
import os
import math
import re
import numpy as np

Cfiles = []
rese = dict()
TF = dict()
TFIDF = dict()
IDF = dict()
incl = dict()
Regex_pattern = r"^//." # for single line comments 
Regex_pattern2 = r"/\*.*?\*/" # for single slash-star line comments
Regex_pattern3 = r'\"(.+?)\"' # for double quoted strings 
Regex_pattern4 = r'\/\*(.|[\r\n])*\*\/' # multiline slash-star comments
# Tell clang.cindex where libclang.dylib is
#clang.cindex.Config.set_library_path("/usr/lib/llvm-6.0/lib")
#index = clang.cindex.Index.create()

def checksource(node):

        if node.location.file == None:
                #print(node.displayname)
                return True
        elif str(node.location.file.name) in Cfiles:
                return True
        else:
                return False

def traversetokens(node):
	global tokendic
	global stats

	for child in node.get_children():
		if checksource(child):
			traversetokens(child)

	for token in node.get_tokens():temporary_code.append(token.spelling)

import pandas as pd
dataset_train=pd.read_csv("data_dir/unlabeled_test.csv")

Cfiles=[]
for i in range(0,25000):
  Cfiles.append('data_dir/test/' + str(dataset_train.iloc[i,1]) +'.cpp')

if __name__ == "__main__":

        #First extract and save all the paths for .cpp files in an array
        #readpaths()

        total_number_documents = len(Cfiles)

        #Check if output file exists or not. If exists delete it
        exists = os.path.isfile('./ASTFeatures.arff')
        if exists:
                os.remove('./ASTFeatures.arff')

        # Tell clang.cindex where libclang.dylib is
        index = clang.cindex.Index.create()
        code_text=[]
        author=[]
        process=[]
        # Generate AST from every filepath f with extention cpp
        for f in range(0,len(Cfiles)):
          try:
            tu = index.parse(Cfiles[f])
            root = tu.cursor  
            temporary_code=[]            
            traversetokens(root)
          except:
            temporary_code=[]
            continue
          temporary_code=" ".join(temporary_code)
          code_text.append(temporary_code)
          author.append(dataset_train.iloc[f,0])
          process.append(dataset_train.iloc[f,1])
          print(f)  

        code_text=pd.DataFrame(code_text)
        author=pd.DataFrame(author)
        process=pd.DataFrame(process)

        X=np.concatenate((process,code_text),axis=1)
        Y=np.concatenate((X,author),axis=1)

        Y=pd.DataFrame(Y)
        Y.to_csv('Final_AST_test.csv', header=True, index=False)



